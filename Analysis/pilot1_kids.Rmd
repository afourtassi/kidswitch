---
title: "WordRec Experiment"
author: "A. Fourtassi & M. Frank"
date: "January 13, 2017"
output:
  html_document:
    number_sections: yes
    toc: yes
---

Libraries.

```{r}
library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(langcog)
theme_set(theme_bw())
```

The following analysis is done using pilot data with 25 subjects.

We plan to collect data for 100 subjects

Data. 

```{r}

#Skip the pre task trials 
#Filter subjects who had no technical problem
#Select subjects who got more than 50% correct answers on the pre task trials

d_norm <- read_delim("Norm_kids.txt", delim = " ") %>%
  filter(type == "Train") #%>%
  #filter(score > 0.5)
  
```

Process norming data

```{r}
concept <- d_norm %>%
  filter(condition == 'concept') %>%
  group_by(distance) %>%
  multi_boot_standard(col = "answer") #%>%
  #rename(concept_dist = conceptOrd,
      #   semDist=mean)


sound <- d_norm %>% 
  filter(condition == 'sound') %>%
  group_by(distance, sameDiff) %>%
  multi_boot_standard(col = "answer") #%>%
 # mutate(contrast= paste(phone1, "/", phone2, sep="")) %>%
  #select(-phone1) %>%
  #select(-phone2)

```
Norming plots

```{r}
plot_concept  <- ggplot(concept, aes(x = distance, y= mean)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .03), size=0.5) +
 
 xlab("distance") +ylab("% different")+ theme_bw()

plot_concept

sound$distance <- factor(sound$distance, levels = c('pl','in','ar1','ar2'))

plot_sound  <- ggplot(sound, aes(x = distance, y= mean, col=sameDiff)) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .03), size=0.5) +
 
 xlab("distance") +ylab("% different")+ theme_bw()

plot_sound
```

Process Switch data

```{r}
#data <- d %>%
#  mutate(correct=ifelse(order==answer, 1, 0))%>%
#  mutate(soun_dist = sound_dist+1) %>%
#  select(-sound_dist) %>%
#  rename(sound_dist = soun_dist)  %>%
#  select(ID, concept_dist, sound_dist, correct, RT) %>%
#  left_join(sound0) %>%
#  left_join(concept0)

data_4 <- d_4 %>%
  mutate(correct=ifelse(order==answer, 1, 0))%>%
  mutate(soun_dist = sound_dist+1) %>%
  select(-sound_dist) %>%
  rename(sound_dist = soun_dist)  %>%
  select(ID, concept_dist, sound_dist, trial, correct, RT) 

data_merge_4 <- data_4 %>%
  mutate(sound_level=ifelse((sound_dist==1 | sound_dist==2), 0.20, 0.75)) %>%
  mutate(concept_level=ifelse((concept_dist==1 | concept_dist==2), 0.37, 0.87)) %>%
  mutate(trial=ifelse((trial==0 | trial==1), 0, 1)) %>%
  select(-sound_dist) %>%
  select(-concept_dist) %>%
  rename(sound_dist=sound_level,
         concept_dist=concept_level)

data_5 <- d_5 %>%
  mutate(correct=ifelse(order==answer, 1, 0))%>%
  mutate(soun_dist = sound_dist+1) %>%
  select(-sound_dist) %>%
  rename(sound_dist = soun_dist)  %>%
  select(ID, concept_dist, sound_dist, trial, correct, RT) 

data_merge_5 <- data_5 %>%
  mutate(sound_level=ifelse((sound_dist==1 | sound_dist==2), 0.20, 0.75)) %>%
  mutate(concept_level=ifelse((concept_dist==1 | concept_dist==2), 0.15, 0.75)) %>%
  mutate(trial=ifelse((trial==0 | trial==1), 0, 1)) %>%
  select(-sound_dist) %>%
  select(-concept_dist) %>%
  rename(sound_dist=sound_level,
         concept_dist=concept_level)

data_merge <- bind_rows(data_merge_4, data_merge_5)



#saveRDS(data, file="data_switch.Rda")

saveRDS(data_merge_4, file="data_switch_all.Rda")


#saveRDS(data_merge, file="data_switch_av.Rda")
```

```{r}
data_plot <- data %>%
  group_by(sound_dist, concept_dist, trial) %>%
  multi_boot_standard(col = "correct")


data_plot_4 <- data_4 %>%
  group_by(sound_dist, concept_dist, trial) %>%
  multi_boot_standard(col = "correct")

data_plot_5 <- data_5 %>%
  group_by(sound_dist, concept_dist, trial) %>%
  multi_boot_standard(col = "correct")
  
  
data_plot_merge_4 <- data_merge_4 %>%
  group_by(sound_dist, concept_dist, trial) %>%
  multi_boot_standard(col = "correct")

data_plot_merge_5 <- data_merge_5 %>%
  group_by(sound_dist, concept_dist, trial) %>%
  multi_boot_standard(col = "correct")

data_plot_all <- data_merge %>%
  group_by(sound_dist, concept_dist, trial) %>%
  multi_boot_standard(col = "correct")

data_plot_2 <- data %>%
  group_by(sound_dist, concept_dist) %>%
  multi_boot_standard(col = "correct")

data_plot_2_l <- data_merge %>%
  group_by(sound_dist, concept_dist) %>%
  multi_boot_standard(col = "correct")

data_plot_C0 <- data_plot %>%
  filter(trial=='0')

data_plot_C1 <- data_plot %>%
  filter(trial=='1')

data_plot_C2 <- data_plot %>%
  filter(trial=='2')

data_plot_C3 <- data_plot %>%
  filter(trial=='3')

#data_plotRT <- data %>%
#  group_by(acousDist, semDist, correct) %>%
#  multi_boot_standard(col = "RT")
```


initial plot
```{r}

ggplot(data_plot_merge_4, 
       aes(x = sound_dist, y = mean, col = factor(concept_dist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  xlab("Auditory distance") +ylab("% different")+
  scale_colour_discrete(name="Visual Dist")+
theme(legend.title = element_text(size=8)) +
  facet_grid(. ~ trial)

ggplot(data_plot_merge_5, 
       aes(x = sound_dist, y = mean, col = factor(concept_dist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  xlab("Auditory distance") +ylab("% different")+
  scale_colour_discrete(name="Visual Dist")+
theme(legend.title = element_text(size=8)) +
  facet_grid(. ~ trial)

ggplot(data_plot_4, 
       aes(x = sound_dist, y = mean, col = factor(concept_dist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  xlab("Auditory distance") +ylab("% different")+
  scale_colour_discrete(name="Visual Dist")+
theme(legend.title = element_text(size=8)) +
  facet_grid(. ~ trial)

ggplot(data_plot_5, 
       aes(x = sound_dist, y = mean, col = factor(concept_dist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  xlab("Auditory distance") +ylab("% different")+
  scale_colour_discrete(name="Visual Dist")+
theme(legend.title = element_text(size=8)) +
  facet_grid(. ~ trial)

  
```

```{r}

ggplot(data_plot_2_l, 
       aes(x = sound_dist, y = mean, col = factor(concept_dist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  xlab("Auditory distance") +ylab("% different")+
  scale_colour_discrete(name="Visual Dist")+
theme(legend.title = element_text(size=8)) 
  
```


```{r}

ggplot(data_plot_l, 
       aes(x = concept_dist, y = mean, col = factor(sound_dist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  xlab("Visual distance") +ylab("% different")+
  scale_colour_discrete(name="Acoustic Dist")+
theme(legend.title = element_text(size=8)) +
  facet_grid(. ~ trial)

```

```{r}
ggplot(data_plot, 
       aes(x = semDist, y = mean, col = factor(acousDist))) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(lty = 2) + 
  scale_colour_solarized() +
  xlab("Visual distance") +ylab("% different")+
  scale_colour_discrete(name="Auditory Dist")+
theme(legend.title = element_text(size=8))

```

Fit the models.
```{r}

#Fit the uniomodal sound condition
sound_data <- d %>%
    filter(condition == "sound")

concept_data <- d %>%
    filter(condition == "concept")

joint_data <- d %>%
    filter(condition == "joint")

#Fit the uniomodal sound condition with a logistic regression
fit_sound <- glm(answer ~ sound_dist, data=sound_data, family = binomial())

##extract coefficient
s_coef <- coef(fit_sound)["sound_dist"]
s_inter <- coef(fit_sound)["(Intercept)"]

#prameters of the sound distribution
s_var=4/(s_coef)
s_sum=-1*s_inter/s_coef

#Fit the uniomodal visual conditon
fit_concept <- glm(answer ~ concept_dist, data=concept_data, family = binomial())

##extract coefficient
c_coef <- coef(fit_concept)["concept_dist"]
c_inter <- coef(fit_concept)["(Intercept)"]

#prameters of the sound distribution
v_var=4/(c_coef)
v_sum=-1*c_inter/c_coef

#Fit the bimodal conditon
fit_joint <- glm(answer ~ sound_dist+concept_dist, data=joint_data, family = binomial())

##extract coefficient
j_coef_a <- coef(fit_joint)["sound_dist"]
j_coef_v <- coef(fit_joint)["concept_dist"]
j_inter <- coef(fit_joint)["(Intercept)"]

#prameters of the sound distribution (approx: the average mean sum equal to 0+4/2=2)
j_var_a=4/(j_coef_a)
j_var_v=4/(j_coef_v)

```


Analysis of the unimodal cases.
```{r}

#Recogniton functions from the unimodal fit 
x <- seq(0, 4, 0.01)

y_sound <- predict(fit_sound, list(sound_dist = x), type="response")
y_concept <- predict(fit_concept, list(concept_dist = x), type="response")

uniS <- data.frame(xS=x,yS=y_sound)
uniV <- data.frame(xV=x,yV=y_concept)

#Recognition functions from the bimodal fit (marginal distributions)
Logistic_a = function (x, A = j_coef_a , B = 2*j_coef_a) {
    1 / (1 + exp(-1*(-B +A * x)))
}

Logistic_v = function (x, A = j_coef_v , B = 2*j_coef_v) {
    1 / (1 + exp(-1*(-B +A * x)))
}

#Plot all these functions in the same graph

##The auditory case
ggplot(sounds, 
       aes(x = sound_dist, y = mean)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(data=uniS,aes(x=xS, y=yS))+
  xlab("Auditory distance") +ylab("% different")+
  scale_y_continuous(limits = c(0, 1))+
  stat_function(fun = Logistic_a, colour="red")

##The visual case
ggplot(concepts, 
       aes(x = concept_dist, y = mean)) + 
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_line(data=uniV,aes(x=xV, y=yV))+
  xlab("Visual distance") +ylab("% different")+
  scale_y_continuous(limits = c(0, 1))+
  stat_function(fun = Logistic_v, colour="red")
 

```

The bimodal case
```{r}

# Bimodal recognition functions

##the bimodal fit 
model_fit <- function (x,y) {
   1/(1 + exp(-x*j_coef_a-y*j_coef_v+2*j_coef_a+2*j_coef_v))
}

##Values of the baseline
model_base <- function (x,y) {
   1/(1 + exp(-x*s_coef-y*c_coef+2*s_coef+2*c_coef))
}

# Add the fit the baeline to data

ms_all <- joint %>% 
  rename(joint = mean) %>%
  left_join(select(concepts, concept_dist, mean) %>% 
              rename(concepts = mean)) %>%
  left_join(select(sounds, sound_dist, mean) %>% 
              rename(sounds = mean)) %>%
  mutate(fit = model_fit(sound_dist, concept_dist)) %>%
  mutate(base = model_base(sound_dist, concept_dist)) %>%
  gather(model, pred, concepts, sounds, base, fit)

#Plot Heat map for the data
ggplot(data = ms_all, aes(x=sound_dist, y=concept_dist, fill=joint)) + 
  geom_tile()+scale_fill_continuous(limits=c(0, 1))+xlab("Auditory distance") +ylab("Visual distance")


#Plot Heatmap for the baseline
mybase <- ms_all %>%
  filter(model=="base")

ggplot(data = mybase, aes(x=sound_dist, y=concept_dist, fill=pred)) + 
  geom_tile()+scale_fill_continuous(limits=c(0, 1))+xlab("Auditory distance") +ylab("Visual distance")

myfilter <- ms_all %>%
  filter(model=="fit" | model=="base")

#Correlation models (baseline and fit) to bimodal data 
ggplot(myfilter, 
       aes(x = pred, y = joint, col = factor(concept_dist), 
           shape = factor(sound_dist))) +
 geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper), 
                  position = position_dodge(width = .1)) + 
  geom_abline(slope = 1, lty = 2) +
  facet_grid(model~.)



```

The modality dominance
```{r}

#Modality dominance coeficent
a_fit=j_var_v/j_var_a
a_base=v_var/s_var
a_Vdom=2*a_base
a_Sdom=0.5*a_base

#Classification thresholds (prob=0.5) for:

##The basline (combination of the unimodal cases)
classif_base = function (x, A=a_base) {
    2*(A+1)-A*x
}

##Best bivariate fit 
classif_fit = function (x, A=a_fit) {
    2*(A+1)-A*x
}

##A baseline for visual domiance
classif_Vdom = function (x, A=a_Vdom) {
    2*(A+1)-A*x
}

##A baseline for auditory domiance
classif_Sdom = function (x, A=a_Sdom) {
    2*(A+1)-A*x
}

#Sample from the baseline bivariate distribution
Gaus_base <- data.frame(x=c(rnorm(1000,0,sqrt(s_var)),rnorm(1000,4,sqrt(s_var))),
          y=c(rnorm(1000,0,sqrt(v_var)),rnorm(1000,4,sqrt(v_var))))

#Plot samples from the bivariate distribution
ggplot(Gaus_base, aes(x,y)) +  stat_density2d(geom="contour",aes(alpha=..level..))+
  scale_alpha_continuous(limits=c(0,0.03),breaks=1e-6*seq(0,10,by=2))+
  stat_function(fun = classif_base, colour = "red") +xlab("Auditory") +ylab("Visual")+ scale_x_continuous(limits = c(-6, 10))+scale_y_continuous(limits = c(-6, 10))

#Sample from the best bivariate fit 
Gaus_fit <- data.frame(x=c(rnorm(1000,0,sqrt(j_var_a)),rnorm(1000,4,sqrt(j_var_a))),
          y=c(rnorm(1000,0,sqrt(j_var_v)),rnorm(1000,4,sqrt(j_var_v))))

#Plot samples from the best bivariate fit
ggplot(Gaus_fit, aes(x,y)) +  stat_density2d(geom="contour",aes(alpha=..level..))+
  scale_alpha_continuous(limits=c(0,0.03),breaks=1e-6*seq(0,10,by=2))+
  stat_function(fun = classif_fit, colour = "red") +xlab("Auditory") +ylab("Visual") + scale_x_continuous(limits = c(-6, 10))+scale_y_continuous(limits = c(-6, 10))

#Modality dominance?
ggplot(Gaus_fit, aes(x,y)) +
  stat_function(fun = classif_base, colour = "red", lty=2) +
  stat_function(fun = classif_Vdom, colour = "blue", lty=2 )+
  stat_function(fun = classif_Sdom, colour = "blue", lty=2)+
  stat_function(fun = classif_fit, colour = "black")+
  xlab("Auditory") +ylab("Visual") + scale_x_continuous(limits = c(-6, 10))+
  scale_y_continuous(limits = c(-6, 10))+theme(aspect.ratio = 1)

```








